# AI 绘画与生图模型入门 (Image Generation Intro)

> 💡 **学习指南**：从 Stable Diffusion 到 Sora，生成式 AI 正在重塑创意产业。本章节将带你理解从“噪点”中诞生“画作”的神奇过程。无论你是设计师还是开发者，理解这些底层原理都将帮助你更好地驾驭 AI 工具。

## 0. 快速上手：如何生成第一张图？

在你开始学习枯燥的原理之前，首先得体验一下"神笔马良"的感觉。AI 绘画不再需要你经过数年的美术训练，只需要一段文字（Prompt），计算机就能为你创造出令人惊叹的图像。

::: info 🎨 常见的 AI 绘画与编辑工具

**🤖 多模态大模型 (对话 + 生图 + 编辑)**
这类模型集成在聊天机器人中，支持通过对话生成图片，并能理解指令进行**修改**（如"把猫换成狗"）。
1.  **GPT-4o (DALL·E 3)**：集成在 ChatGPT 中，语义理解极强，支持局部重绘（Inpainting）和对话式修改。
2.  **Gemini (Imagen 3)**：Google 的顶级模型，生成速度快，写实风格出色，支持复杂的逻辑指令。
3.  **通义万相 (Wanx) / Qwen**：阿里通义实验室出品，中文理解能力优秀，支持多种艺术风格。

**🎨 专业创作工具 (画质与艺术优先)**
1.  **Midjourney**：目前艺术感与审美最顶尖的工具（运行在 Discord/Web），支持扩图（Zoom）、平移（Pan）和局部重绘。
2.  **Flux**：当前最强开源模型，文字生成（Typography）能力极强，画质媲美 Midjourney。

**💻 本地/开源生态 (极致控制)**
1.  **Stable Diffusion (WebUI/ComfyUI)**：拥有最庞大的插件生态（ControlNet, LoRA），可精确控制画面构图、姿态和风格。
2.  **ComfyUI**：基于节点的工作流工具，适合构建复杂的自动化生图管线。

:::

### 0.1 为什么要学习 AI 绘画？(Why GenAI?)

你可能会问：*“网上图片那么多，我为什么要用 AI 生成？”* 或者 *“我是程序员，为什么要懂画画？”*

这并非为了替代人类画家，而是因为 **生成式 AI (Generative AI)** 带来了一种全新的生产力范式：

#### 1. 效率的质变：从小时到秒
*   **传统绘画**：构思 -> 草图 -> 线稿 -> 上色 -> 光影 -> 细化。一张精美插画可能需要数天。
*   **AI 生成**：构思 -> 提示词 -> 生成。只需要几秒钟。这让你可以在 10 分钟内尝试 100 种不同的构图和风格。

#### 2. 创意的扩充：打破技能壁垒
*   **传统**：你脑子里有一个绝妙的创意，但你的手画不出来。
*   **AI**：它是你的“手”。只要你能描述出来，它就能画出来。它降低了表达的门槛，让每个人都能成为创作者。

#### 3. 可编程的艺术
*   对于开发者来说，AI 模型不仅仅是画笔，更是**API**。你可以将它集成到游戏、网站或应用中，实现动态生成头像、实时渲染材质等过去无法想象的功能。

## 1. 核心架构：解耦的艺术 (The Big Picture)

如果要让电脑学会画画，直接处理像素太累了（一张 1024x1024 的图有 300 多万个数值）。聪明的科学家们设计了一套分工明确的流水线。

我们可以把 AI 画家看作一个由三个部门组成的**创意工作室**：

### 2.1 角色分工

*   **👁️ 眼睛：VAE (变分自编码器)**
    *   **职责**：负责“翻译”。
    *   **编码 (Encode)**：把人类看的高清大图（Pixel Space），压缩成机器好处理的“浓缩特征图”（Latent Space）。
    *   **解码 (Decode)**：把机器画好的特征图，还原成我们能看懂的高清大图。
    *   *作用：大大降低了计算量，让 AI 可以在家用显卡上运行。*

*   **🧠 大脑：UNet / DiT (去噪模型)**
    *   **职责**：负责“作画”。
    *   **工作原理**：它主要在潜空间（Latent Space）工作。它的核心技能是**预测噪声**。给它一张模糊的噪点图，它能算出“这上面哪部分是噪点”，然后减去噪点，画面就清晰了。
    *   *进化*：早期的 Stable Diffusion 使用 **UNet** 架构；最新的 Sora 和 SD3 使用 **DiT (Transformer)** 架构，逻辑能力更强。

*   **👂 耳朵：CLIP / T5 (文本编码器)**
    *   **职责**：负责“听懂人话”。
    *   **工作原理**：它把你输入的 `Prompt`（如 "一只猫"）转换成计算机能理解的**数学向量 (Embeddings)**，并交给大脑，告诉它该画什么。

<ImageGenArchitecture />

## 3. 视觉模型：潜空间 (Latent Space)

理解 **潜空间 (Latent Space)** 是理解现代 AI 的关键。

想象一下，如果我们要描述一个人：
*   **Pixel Space (像素空间)**：我们需要描述他脸上每一个毛孔的颜色（几百万个数据）。
*   **Latent Space (潜空间)**：我们只需要描述几个关键特征——“性别：男，发型：短发，表情：笑，眼镜：有”。

AI 并不是在画布上一点点涂颜色，而是在这个高维的“特征空间”里寻找坐标。

*   **压缩**：大图 -> 浓缩为 Latent 数值。
*   **操作**：在这个空间里移动（比如把“表情”这个维度的数值调大），图片就会从哭脸变成笑脸。

<LatentSpaceViz />

## 4. 生成机制：从噪声到画作 (Generation Process)

AI 是如何凭空变出画面的？主要有两种主流机制。

### 4.1 扩散模型 (Diffusion) —— 雕刻家

扩散模型的灵感来源于物理学中的热力学扩散。它包含两个过程：

1.  **破坏 (Forward)**：像往清水里滴墨水，或者把照片磨砂化。一步步加噪点，直到变成纯噪声。
2.  **重构 (Reverse)**：AI 学习这一过程的**逆过程**。从一片雪花屏开始，猜测“这里原本应该是什么”，一点点去除噪声，直到露出清晰的画面。

*这就像米开朗基罗雕刻大卫像：“大卫就在石头里，我只是去掉了多余的部分。”*

<DiffusionProcessDemo />

### 4.2 流匹配 (Flow Matching) —— 传送门

**为什么 Diffusion 有时很慢？** 因为从“噪声”到“图片”的还原路径，Diffusion 往往走的是一条弯弯曲曲的、充满随机性的路（随机游走）。

最新的模型（如 **Flux**, **Stable Diffusion 3**）采用了 **Flow Matching (流匹配)** 技术。

*   **核心思想**：我们不再盲目去噪，而是寻找从“噪声分布”到“图像分布”的 **最优传输路径 (Optimal Transport)**。
*   **优势**：这条路径是笔直的。AI 不需要走 50 步，往往只需要走几步（比如 4-8 步），就能顺着直线“滑”到终点。这也是为什么 Flux 既快又好的原因。

<FlowMatchingDemo />

## 5. 操控机制：提示词的艺术 (Prompting)

AI 画家空有一身技艺，怎么听懂你的指挥？

这就涉及到了 **交叉注意力机制 (Cross-Attention)**。

1.  **翻译**：你的 Prompt（如 "cyberpunk"）被 Text Encoder 变成了一串向量。
2.  **注入**：这些向量被“注射”进生成模型的每一层。
3.  **关注**：当 AI 在画画时，它会不断回头看这些向量。
    *   画背景时，它会关注 "city", "neon lights"。
    *   画主体时，它会关注 "cat", "glasses"。

这就是为什么 Prompt 中词语的顺序和权重如此重要。

<PromptVisualizer />

## 6. 总结 (Summary)

AI 绘画技术并不是魔法，而是**统计学、几何学与计算机科学**的完美结合。

*   **VAE** 帮我们压缩了世界。
*   **Diffusion/Flow** 帮我们从混沌中建立秩序。
*   **Transformer** 帮我们连接了语言与视觉。

当你点击“生成”的那一刻，你实际上是指挥着数亿个参数，在高维空间中进行了一次精确的数学迁徙，最终将一个可能存在的平行宇宙坍缩到了你的屏幕上。

## 附录：常用术语表 (Vocabulary)

| 术语 | 英文 | 解释 |
| :--- | :--- | :--- |
| **文生图** | Text-to-Image | 输入文字生成图像的任务。 |
| **图生图** | Image-to-Image | 输入参考图和文字生成新图像的任务。 |
| **扩散模型** | Diffusion Model | 通过逐步去噪生成图像的一类模型架构。 |
| **潜空间** | Latent Space | 压缩后的图像特征空间，计算效率更高。 |
| **VAE** | Variational Autoencoder | 负责图像与潜空间之间转换的编解码器。 |
| **LoRA** | Low-Rank Adaptation | 一种轻量级微调技术，用于给模型添加特定画风或角色。 |
| **种子** | Seed | 初始化噪声的随机数种子，决定了生成的初始状态。 |
| **提示词** | Prompt | 指挥 AI 生成内容的文本指令。 |
| **采样器** | Sampler | 决定去噪过程具体算法的组件（如 Euler, DPM++）。 |
